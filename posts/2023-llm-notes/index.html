<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>关于LLM的笔记 | Woffee&#39;s notes</title>

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">    
<meta name="viewport" content="width=device-width,minimum-scale=1">
<meta name="description" content="GPT-3 的出现可以说是一个分水岭">
<meta name="generator" content="Hugo 0.110.0">


  <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">


<link rel="stylesheet" href="/css/style.css">



<link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon" />







  </head>

  <body>
    <nav class="navigation">
	
		<a href="/"> <span class="arrow">←</span>Home</a>
	
	<a href="/posts">Archive</a>
	<a href="/tags">Tags</a>
	<a href="/about">About</a>

	

	
</nav>


    <main class="main">
      

<section id="single">
    <h1 class="title">关于LLM的笔记</h1>

    <div class="tip">
        <time datetime="2023-02-15 11:55:41 -0500 EST">Feb 15, 2023</time>
        <span class="split">
          ·
        </span>
        <span>
          71 words
        </span>
        <span class="split">
          ·
        </span>
        <span>
          1 minute read
        </span>
    </div>

    
    


    <div class="content">
      <p>GPT-3 的出现可以说是一个分水岭</p>
<p>原文链接：<a href="https://zhuanlan.zhihu.com/p/597586623" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/597586623</a></p>
<h2 id="四大范式">四大范式 <a href="#%e5%9b%9b%e5%a4%a7%e8%8c%83%e5%bc%8f" class="anchor">🔗</a></h2><p><p class="markdown-image">
  <img src="/imgs/nlp_4_paradigms.png" alt="四大范式"  />
</p></p>
<ul>
<li>Feature Engineering：即使用文本特征，例如词性，长度等，在使用机器学习的方法进行模型训练。（无预训练语言模型）</li>
<li>Architecture Engineering：在W2V基础上，利用深度模型，加上固定的embedding。（有固定预训练embedding，但与下游任务无直接关系）</li>
<li>Objective Engineering：在bert 的基础上，使用动态的embedding，在加上fine-tuning。（有预训练语言模型，但与下游任务有gap）</li>
<li>Prompt Engineering：直接利用与训练语言模型辅以特定的prompt。（有预训练语言模型，但与下游任务无gap）</li>
</ul>
<h3 id="gpt-3-的出现可以说是一个分水岭">GPT-3 的出现可以说是一个分水岭 <a href="#gpt-3-%e7%9a%84%e5%87%ba%e7%8e%b0%e5%8f%af%e4%bb%a5%e8%af%b4%e6%98%af%e4%b8%80%e4%b8%aa%e5%88%86%e6%b0%b4%e5%b2%ad" class="anchor">🔗</a></h3><p>在GPT-3之前，就是第三范式，GPT-3之后，就进入了第四范式</p>
<p><p class="markdown-image">
  <img src="/imgs/prompting.png" alt="Prompting"  />
</p></p>
<h3 id="gpt-3-发布后带来的影响">GPT-3 发布后带来的影响 <a href="#gpt-3-%e5%8f%91%e5%b8%83%e5%90%8e%e5%b8%a6%e6%9d%a5%e7%9a%84%e5%bd%b1%e5%93%8d" class="anchor">🔗</a></h3><h4 id="影响一中间任务的消亡">影响一：中间任务的消亡 <a href="#%e5%bd%b1%e5%93%8d%e4%b8%80%e4%b8%ad%e9%97%b4%e4%bb%bb%e5%8a%a1%e7%9a%84%e6%b6%88%e4%ba%a1" class="anchor">🔗</a></h4><p>按理说，“中间任务”就不应该出现，而之所以会存在，这是NLP技术发展水平不够高的一种体现。</p>
<p>自从Bert／GPT出现之后，其实就没有必要做这些中间任务了，</p>
<h4 id="影响二不同研究方向技术路线的统一">影响二：不同研究方向技术路线的统一 <a href="#%e5%bd%b1%e5%93%8d%e4%ba%8c%e4%b8%8d%e5%90%8c%e7%a0%94%e7%a9%b6%e6%96%b9%e5%90%91%e6%8a%80%e6%9c%af%e8%b7%af%e7%ba%bf%e7%9a%84%e7%bb%9f%e4%b8%80" class="anchor">🔗</a></h4><p>自从Bert/GPT模型诞生后，出现了明显的技术统一趋向。首先，NLP中不同的子领域，其特征抽取 器都逐渐从LSTM/CNN统一到Transformer上</p>
<h4 id="影响三很多nlp子领域不再具备独立研究价值">影响三：很多NLP子领域不再具备独立研究价值 <a href="#%e5%bd%b1%e5%93%8d%e4%b8%89%e5%be%88%e5%a4%9anlp%e5%ad%90%e9%a2%86%e5%9f%9f%e4%b8%8d%e5%86%8d%e5%85%b7%e5%a4%87%e7%8b%ac%e7%ab%8b%e7%a0%94%e7%a9%b6%e4%bb%b7%e5%80%bc" class="anchor">🔗</a></h4><h2 id="过渡期以gpt-30为代表的自回归语言模型prompting模式占据统治地位">过渡期：以GPT 3.0为代表的“自回归语言模型+Prompting”模式占据统治地位 <a href="#%e8%bf%87%e6%b8%a1%e6%9c%9f%e4%bb%a5gpt-30%e4%b8%ba%e4%bb%a3%e8%a1%a8%e7%9a%84%e8%87%aa%e5%9b%9e%e5%bd%92%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8bprompting%e6%a8%a1%e5%bc%8f%e5%8d%a0%e6%8d%ae%e7%bb%9f%e6%b2%bb%e5%9c%b0%e4%bd%8d" class="anchor">🔗</a></h2><p>Prompt其实是一个过渡期的技术，之所以有 Prompt这个技术，是因为LLM暂时不具备完全理解自然语言的能力。需要人们准确告诉它任务细节，激活LLM里与该任务相关的神经节点。</p>
<p>这里有一个假设，或者说是前提，就是LLM具备自主学习能力。在此之上，我们才可以谈Prompt。</p>
<p>最近几年相关的文章可分为：</p>
<ul>
<li>Few shot prompting</li>
<li>Zero shot prompting</li>
<li>In Context Learning</li>
<li>Instruct</li>
</ul>
<p>这些名词实际上都是在说prompt，但只是具体做法不同，所以叫法也不同。</p>
<p>Fine-tuning中：是预训练语言模型“迁就“各种下游任务。具体体现就是上面提到的通过引入各种辅助任务loss，将其添加到预训练模型中，然后继续pre-training，以便让其更加适配下游任务。总之，这个过程中，预训练语言模型做出了更多的牺牲。</p>
<p>Prompting中，是各种下游任务“迁就“预训练语言模型。具体体现也是上面介绍的，我们需要对不同任务进行重构，使得它达到适配预训练语言模型的效果。总之，这个过程中，是下游任务做出了更多的牺牲。</p>
<p>Prompt 分为离散和连续两种。离散就是说我们的prompt是一个个 token。
连续是说，我们的prompt 是一个 embedding。</p>
<h3 id="连续-prompting">连续 Prompting <a href="#%e8%bf%9e%e7%bb%ad-prompting" class="anchor">🔗</a></h3><p><p class="markdown-image">
  <img src="/imgs/continuous_prompting.png" alt="连续 Prompting"  />
</p></p>
<h3 id="离散-prompting">离散 Prompting <a href="#%e7%a6%bb%e6%95%a3-prompting" class="anchor">🔗</a></h3><p><p class="markdown-image">
  <img src="/imgs/prompting1.png" alt="prompting1"  />
</p></p>
<p>CoT的意思是让LLM模型明白一个道理；就是 在推理过程中，步子不要迈得太大，否则很容易出错，改变思维模式，化大问题为小问题</p>
<p><p class="markdown-image">
  <img src="/imgs/prompting2.png" alt="prompting1"  />
</p></p>
<p>“Self-Consistency”则不然，它要求LLM输出多个 不同的推理过程和答案，然后采用投票的方式选出最佳答案，思路非常简单直接，但是效果也确实好</p>
<p><p class="markdown-image">
  <img src="/imgs/prompting3.png" alt="prompting1"  />
</p></p>
<h2 id="从预训练模型走向通用人工智能">从预训练模型走向通用人工智能 <a href="#%e4%bb%8e%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b%e8%b5%b0%e5%90%91%e9%80%9a%e7%94%a8%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd" class="anchor">🔗</a></h2><p>人适配 LLM的典型例子，比如绞尽脑汁去尝试各种不同的prompt，以试图找到好的提示语，</p>
<p>ChatGPT的最大贡献在于：基本实现了理想LLM的接口层，让LLM适配人的习惯命令表 达方式，而不是反过来让人去适配LLM，绞尽脑汁地想出一个能Work的命令（这就是instruct技术 出来之前，prompt技术在做的事情），而这增加了LLM的易用性和用户体验。是 InstructGPT/ChatGPT首先意识到这个问题，并给出了很好的解决方案，这也是它最大的技术贡 献。相对之前的few shot prompting，它是一种更符合人类表达习惯的人和LLM进行交互的人机接口技术。</p>
    </div>

    
        <div class="tags">
            
                <a href="/tags/llm">LLM</a>
            
                <a href="/tags/nlp">NLP</a>
            
        </div>
    
    
    

</section>


    </main>
    
    <footer id="footer">
    

    <div class="copyright">
    
       © Copyright 
       2023 
       <span class="split">
        <svg fill="#bbbbbb" width="15" height="15" version="1.1" id="heart-15" xmlns="http://www.w3.org/2000/svg" width="15px" height="15px" viewBox="0 0 15 15">
  <path d="M13.91,6.75c-1.17,2.25-4.3,5.31-6.07,6.94c-0.1903,0.1718-0.4797,0.1718-0.67,0C5.39,12.06,2.26,9,1.09,6.75&#xA;&#x9;C-1.48,1.8,5-1.5,7.5,3.45C10-1.5,16.48,1.8,13.91,6.75z"/>
</svg>
       </span>
       
    
    </div>

    
      <div class="powerby">
        Powered by <a href='http://www.gohugo.io/'>Hugo</a> Theme By <a href='https://github.com/nodejh/hugo-theme-mini'>nodejh</a>
      </div>
    
</footer>



  </body>
</html>
